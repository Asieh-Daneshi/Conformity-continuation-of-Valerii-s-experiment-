---
title: "Analysis (Decision)"
author: "Valerii Chirkov"
date: '2022-09-16'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

# load fronts
# library(extrafont)
# extrafont::font_import()
```

```{r}
library("pacman")
p_load(tidyverse, brms, ggExtra, bayesplot, wesanderson, hrbrthemes, pROC)

data <- readRDS(file = "data/data_filtered.rds")

head(data)

```


## How do sensorimotor processes influence social decision-making?

**Hypotheses**

The rate of compliance with group decisions (`decision`) will be larger for:
- congruent trials (`congruency`)
- larger group (`c_n_agents`)

## Logistic Regression

### Model 1: decision ~ 1 + c_n_agents * congruency

```{r results='hide'}

# Set of slighlty informative priors
m1.priors <- c(
  prior(normal(0, 1), class = Intercept),
  prior(normal(0, 0.01), coef = "c_n_agents", class = b),
  prior(normal(0, 0.01), coef = "congruency1", class = b),
  prior(normal(0, 0.01), coef = "c_n_agents:congruency1", class = b)
)

m1.formula <- brmsformula(decision ~ 1 + c_n_agents * congruency)

m1.fit <- brm(
  formula = m1.formula,
  data = data,
  family = bernoulli(link = "logit"),
  prior = m1.priors,
  cores = 4,
  seed = 42)

```

```{r}

summary(m1.fit)

```

```{r}

round(fixef(m1.fit), 3)

```


```{r}

m1.df_fit <- as.data.frame(m1.fit) %>%
  dplyr::rename(
    n_agents = `b_c_n_agents`,
    intercept = `b_Intercept`,
    congruency = `b_congruency1`,
    n_agents_congruency = `b_c_n_agents:congruency1`
  )

mcmc_areas(
  m1.df_fit,
  pars = c("n_agents", "congruency", "n_agents_congruency"),
  prob = 0.8, # 80% intervals
  prob_outer = 0.99, # 99%
  point_est = "median"
) + ggplot2::labs(
  title = "Posterior parameter distributions",
  subtitle = "with medians and 80% intervals"
)

```


```{r}
plot(conditional_effects(m1.fit), ask = FALSE)
```


```{r eval=FALSE}

p <- conditional_effects(m1.fit, ask = F, effects = "c_n_agents:congruency")

plot(p, plot = FALSE)[[1]] +
  theme_bw() +
  labs(x = "Number of agens", y = "Group allignment", title = "Decision")

```

## Posterior Predictive Checks


### PSIS-LOO diagnostics 


```{r}
# Useful to check outlines (k > 0.7)
plot(loo(m1.fit))

```

```{r}

pp_check(m1.fit, type = "bars", ndraws = 10)

```

### Posterior predictive checks by congrouency

```{r}

ppc_bars_grouped(
  data$decision,
  yrep = posterior_predict(m1.fit, ndraws = 100),
  group = data$congruency
)

```

### Posterior predictive checks by the number of agents

```{r}

ppc_bars_grouped(
  data$decision,
  yrep = posterior_predict(m1.fit, ndraws = 100),
  group = data$n_agents
)

```

### Posterior predictive checks for congruency x the number of agents

```{r}

ppc_bars_grouped(
  data$decision,
  yrep = posterior_predict(m1.fit, ndraws = 100),
  group = (data %>% mutate(congruency_n_agents = paste0(congruency, "_", n_agents)))$congruency_n_agents
)

```

SEE: https://www.rdocumentation.org/packages/brms/versions/0.6.0/topics/hypothesis

```{r}

hypothesis(m1.fit, 
           c("c_n_agents > 0", 
             "congruency1 < 0", 
             "c_n_agents:congruency1 < 0"), alpha = 0.01)

```

## Sensitivity analysis for BF

```{r, eval=FALSE, include=FALSE}

get_prior(m1.formula, data)

```

### Slightly informative priors

```{r results='hide', eval=TRUE}
priors <- c(
  prior(normal(0, 1), class = Intercept),
  prior(normal(0, 0.01), class = b),
  prior(normal(0.01, 0.01), coef="c_n_agents", class = b),
  prior(normal(-0.01, 0.01), coef="congruency1", class = b)
)

m0.0.fit <- brm(
  formula = decision ~ 1, prior = priors %>% filter(class == "Intercept" ),
  data = data, family = bernoulli(link = "logit"), warmup = 2000, iter = 10000,
  cores = 4, save_pars = save_pars(all = TRUE), seed = 42)

m0.0.bridge_sampler <- bridge_sampler(m0.0.fit, silent = TRUE)

m0.1.fit <- brm(
  formula = decision ~ 1 + congruency + c_n_agents:congruency, 
  prior = priors %>% filter(coef != "c_n_agents" ),
  data = data, family = bernoulli(link = "logit"), warmup = 2000, iter = 10000,
  cores = 4, save_pars = save_pars(all = TRUE), seed = 42)

m0.1.bridge_sampler <- bridge_sampler(m0.1.fit, silent = TRUE)

m0.2.fit <- brm(
  formula = decision ~ 1 + c_n_agents + c_n_agents:congruency,
  prior = priors %>% filter(coef != "congruency1" ),
  data = data, family = bernoulli(link = "logit"), warmup = 2000, iter = 10000,
  cores = 4, save_pars = save_pars(all = TRUE), seed = 42)

m0.2.bridge_sampler <- bridge_sampler(m0.2.fit, silent = TRUE)

m0.3.fit <- brm(
  formula = decision ~ 1 + c_n_agents + congruency,
  prior = priors,
  data = data, family = bernoulli(link = "logit"), warmup = 2000, iter = 10000,
  cores = 4, save_pars = save_pars(all = TRUE), seed = 42)

m0.3.bridge_sampler <- bridge_sampler(m0.3.fit, silent = TRUE)

m1.fit <- brm(
  formula = decision ~ 1 + c_n_agents*congruency, prior = priors,
  data = data, family = bernoulli(link = "logit"), warmup = 2000, iter = 10000,
  cores = 4, save_pars = save_pars(all = TRUE), seed = 42)

m1.bridge_sampler <- bridge_sampler(m1.fit, silent = TRUE)

```

```{r, eval=TRUE}
print(bayes_factor(m1.bridge_sampler, m0.0.bridge_sampler))
print(bayes_factor(m1.bridge_sampler, m0.1.bridge_sampler))
print(bayes_factor(m1.bridge_sampler, m0.2.bridge_sampler))
print(bayes_factor(m1.bridge_sampler, m0.3.bridge_sampler))
```

### Quite informative priors

```{r results='hide', eval=TRUE}
priors <- c(
  prior(normal(0, 1), class = Intercept),
  prior(normal(0, 0.01), class = b),  # for interactions
  prior(normal(0.02, 0.01), coef = "c_n_agents", class = b),
  prior(normal(-0.02, 0.01), coef = "congruency1", class = b)
)


m0.0.fit <- brm(
  formula = decision ~ 1, prior = priors %>% filter(class == "Intercept" ),
  data = data, family = bernoulli(link = "logit"), warmup = 2000, iter = 10000,
  cores = 4, save_pars = save_pars(all = TRUE), seed = 42)

m0.0.bridge_sampler <- bridge_sampler(m0.0.fit, silent = TRUE)

m0.1.fit <- brm(
  formula = decision ~ 1 + congruency + c_n_agents:congruency, 
  prior = priors %>% filter(coef != "c_n_agents" ),
  data = data, family = bernoulli(link = "logit"), warmup = 2000, iter = 10000,
  cores = 4, save_pars = save_pars(all = TRUE), seed = 42)

m0.1.bridge_sampler <- bridge_sampler(m0.1.fit, silent = TRUE)

m0.2.fit <- brm(
  formula = decision ~ 1 + c_n_agents + c_n_agents:congruency,
  prior = priors %>% filter(coef != "congruency1" ),
  data = data, family = bernoulli(link = "logit"), warmup = 2000, iter = 10000,
  cores = 4, save_pars = save_pars(all = TRUE), seed = 42)

m0.2.bridge_sampler <- bridge_sampler(m0.2.fit, silent = TRUE)

m0.3.fit <- brm(
  formula = decision ~ 1 + c_n_agents + congruency,
  prior = priors,
  data = data, family = bernoulli(link = "logit"), warmup = 2000, iter = 10000,
  cores = 4, save_pars = save_pars(all = TRUE), seed = 42)

m0.3.bridge_sampler <- bridge_sampler(m0.3.fit, silent = TRUE)

m1.fit <- brm(
  formula = decision ~ 1 + c_n_agents*congruency, prior = priors,
  data = data, family = bernoulli(link = "logit"), warmup = 2000, iter = 10000,
  cores = 4, save_pars = save_pars(all = TRUE), seed = 42)

m1.bridge_sampler <- bridge_sampler(m1.fit, silent = TRUE)

```

```{r, eval=TRUE}

print(bayes_factor(m1.bridge_sampler, m0.0.bridge_sampler))
print(bayes_factor(m1.bridge_sampler, m0.1.bridge_sampler))
print(bayes_factor(m1.bridge_sampler, m0.2.bridge_sampler))
print(bayes_factor(m1.bridge_sampler, m0.3.bridge_sampler))

```

### Uninformative priors

```{r results='hide'}

BF <- data.frame(b_sd = NA, int_sd = NA, no_n_agents = NA, no_congruency = NA, no_interaction = NA)

n <- 1

int_sd <- c(1)
b_sd <- c(0.1, 0.05, 0.01, 0.005, 0.001)

for (i in 1:length(int_sd)) {
  for (j in 1:length(b_sd)) {

priors <- c(
  set_prior(paste0("normal(0, ", int_sd[i], ")"), class = "Intercept"),
  set_prior(paste0("normal(0, ", b_sd[j], ")"), class = "b")
)

m0.1.fit <- brm(
  formula = decision ~ 1 + congruency + c_n_agents:congruency, prior = priors,
  data = data, family = bernoulli(link = "logit"), warmup = 2000, iter = 10000,
  cores = 4, save_pars = save_pars(all = TRUE), seed = 42)

m0.1.bridge_sampler <- bridge_sampler(m0.1.fit, silent = TRUE)

m0.2.fit <- brm(
  formula = decision ~ 1 + c_n_agents + c_n_agents:congruency, prior = priors,
  data = data, family = bernoulli(link = "logit"), warmup = 2000, iter = 10000,
  cores = 4, save_pars = save_pars(all = TRUE), seed = 42)

m0.2.bridge_sampler <- bridge_sampler(m0.2.fit, silent = TRUE)

m0.3.fit <- brm(
  formula = decision ~ 1 + congruency + c_n_agents, prior = priors,
  data = data, family = bernoulli(link = "logit"), warmup = 2000, iter = 10000,
  cores = 4, save_pars = save_pars(all = TRUE), seed = 42)

m0.3.bridge_sampler <- bridge_sampler(m0.3.fit, silent = TRUE)

m1.fit <- brm(
  formula = decision ~ 1 + c_n_agents * congruency, prior = priors,
  data = data, family = bernoulli(link = "logit"), warmup = 2000, iter = 10000,
  cores = 4, save_pars = save_pars(all = TRUE), seed = 42)

m1.bridge_sampler <- bridge_sampler(m1.fit, silent = TRUE)


BF[n, "b_sd"] <- b_sd[j]
BF[n, "int_sd"] <- int_sd[i]
BF[n, "no_n_agents"] <- bayes_factor(m1.bridge_sampler, m0.1.bridge_sampler)$bf
BF[n, "no_congruency"] <- bayes_factor(m1.bridge_sampler, m0.2.bridge_sampler)$bf
BF[n, "no_interaction"] <- bayes_factor(m1.bridge_sampler, m0.3.bridge_sampler)$bf

n = n + 1
  }
}
```


```{r echo=FALSE}

BF %>% 
  pivot_longer(names_to = "model", values_to = "bf", 
               cols = c("no_n_agents", "no_congruency", "no_interaction")) %>%
  ggplot(aes(color = model, y = log(bf), x = as.factor(b_sd))) +
    geom_line(aes(group = model), color = 'gray') +
    geom_point(size = 4, alpha  = 0.6) +
    theme_bw()

```

```{r}
sessionInfo()
```

```{r}
devtools::session_info()
```


